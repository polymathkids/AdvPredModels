{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19HNg2RQUj-AXWeyhb1aNU_Rd78geW_js",
      "authorship_tag": "ABX9TyOe2tG+wxo1gceHKlg7KR2k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/polymathkids/AdvPredModels/blob/main/HW7Q2_Staff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2 HW7 AMP Staff Graded:\n",
        "\n",
        "Consider the following data sets:\n",
        "\n",
        "TexasCityDistanceMatrix.csv\n",
        "TexasCityKey.csv\n",
        "\n",
        "This data is a subset of the National Bureau of Economic Research's City Distances database. The TexasCityDistanceMatrix.csv file contains a sparse, square matrix, in which the cells represent the distance between the cities on the respective row and column. Each row and column represents an individual city and their distance to the cities on the corresponding row/columns. The TexasCityKey.csv file contains a key for the id's in the other file, connecting the IDs to the names of the cities. Note there are repeated city names in this file. This is not an error nor does it require any data cleaning, as some cities are not uniquely named. (Hint: When you load the TexasCityDistanceMatrix.csv file, indicate the first column as indices.)"
      ],
      "metadata": {
        "id": "AAjP56TPAj4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# read in the CSV file as a DataFrame\n",
        "DistMatrix = pd.read_csv('/content/drive/MyDrive/AMP/TexasCityDistanceMatrix.csv', index_col = 0)\n",
        "TexasKey = pd.read_csv('/content/drive/MyDrive/AMP/TexasKey.csv')\n",
        "\n",
        "# convert the DataFrame to a matrix\n",
        "CityDistMatrix = DistMatrix.values"
      ],
      "metadata": {
        "id": "OqxpPpAMAu-h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. What is the maximum value in this matrix? What does this imply about the missing values of the matrix?"
      ],
      "metadata": {
        "id": "qbms8rUcAvWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find the maximum value of the matrix\n",
        "max_dist = np.max(CityDistMatrix)\n",
        "\n",
        "# print the maximum value\n",
        "print(max_dist)\n",
        "\n",
        "# ignore nan values\n",
        "max_dist = np.nanmax(CityDistMatrix)\n",
        "print(max_dist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijDDXTvLAxR6",
        "outputId": "d0558f25-1e90-4b24-869f-31eb590fd639"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nan\n",
            "99.99971353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The maximum value in the matrix initially returned an nan value but if nan values are ignored, the max value returned in 99.999. This tells me that the matrix only defines distances between cities that are less than 100 and nan values are likely those values that are greater than 100 miles apart."
      ],
      "metadata": {
        "id": "c4LauyWObe5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "b. What is the closest location to Katy city\"? How many locations are within 25 miles of Flower Mound town\" (excluding the town itself)?"
      ],
      "metadata": {
        "id": "FR4AmNjtAxnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Need to remove 0's in dist matrix or closet location will always be itself\n",
        "DistMatrix_z = DistMatrix.replace(0, np.nan)\n",
        "\n",
        "# find the row in Texas Key that equals 'Katy city'\n",
        "matching = TexasKey.loc[TexasKey['Name'] == 'Katy city']\n",
        "#store the value of the Place column as the index we are looking for\n",
        "city_index = matching['Place']\n",
        "\n",
        "#grab the row for Katy city using the saved index value\n",
        "min2Katy = DistMatrix_z.iloc[city_index,:].idxmin(axis = 1, skipna = True)\n",
        "#get just the value of the place and strip away the brackets and V prefix\n",
        "min2Katy = str(min2Katy.values)\n",
        "min2Katy = int(min2Katy[3:-2])\n",
        "#use result to find the matching name in TexasKey\n",
        "print(TexasKey[TexasKey['Place'] == min2Katy])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSAeJzs2Azhn",
        "outputId": "f90b77a4-d23a-42e5-a858-a667d26f6182"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Place            Name\n",
            "1128   1129  Oak Grove town\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The location closest to Katy city is Oak Grove town.\n"
      ],
      "metadata": {
        "id": "RDY1doWNSRa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find the row in Texas Key that equals 'Flower Mound town'\n",
        "matching = TexasKey.loc[TexasKey['Name'] == 'Flower Mound town']\n",
        "#store the value of the Place column as the index we are looking for\n",
        "city_index = matching['Place']\n",
        "\n",
        "#save the values  in the row for Flower Mound town\n",
        "#using the saved index value that are less than or equal to 25\n",
        "#use DistMatrix_z that excludes the 0 values\n",
        "FlowerMound = DistMatrix_z.iloc[city_index,:][DistMatrix_z.iloc[city_index,:]<=25].dropna(axis =1)\n",
        "print(len(FlowerMound.columns)) #returns number of towns within 25 miles\n",
        "FlowerMound = list(FlowerMound.columns) #grab col names and save as list\n",
        "for i in range(len(FlowerMound)):\n",
        "    FlowerMound[i] = FlowerMound[i][1:] #remove V prefix\n",
        "    #FlowerMound is now saved as searchable locations for towns w/i 25 mi of FlowerMound\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np6i0UuLSVZw",
        "outputId": "0cea5b57-71a8-4d2f-d056-2213df686e1d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 5 locations within 25 miles of Flower Mound, excluding the town of Flower Mound itself."
      ],
      "metadata": {
        "id": "PgxXkkTzXZaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "c. Find the time it takes to sum all of the elements in the matrix."
      ],
      "metadata": {
        "id": "yNC5bajjAz6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "np.sum(CityDistMatrix)\n",
        "end = time.time()\n",
        "print(end-start)"
      ],
      "metadata": {
        "id": "0yUSrHlKA1iT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "831749e1-f58c-4e06-d2ad-dc87a75a380d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.002972126007080078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Suppose you are interested in examining only the relationships between cities that are relatively close to one another. For all distances greater than 50 miles apart, set the value to zero. Additionally, set the missing values equal to zero. Compute the time it takes to sum all the elements in this new matrix. How does this compare to your previous results?"
      ],
      "metadata": {
        "id": "9X7QqT1bA14P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#replace values > 50 with 0\n",
        "CityDistMatrix[CityDistMatrix>50] = 0\n",
        "\n",
        "#replace nan values with 0\n",
        "CityDistMatrix = np.nan_to_num(CityDistMatrix, nan = 0)\n",
        "\n",
        "start = time.time()\n",
        "np.sum(CityDistMatrix)\n",
        "end = time.time()\n",
        "print(end-start)\n"
      ],
      "metadata": {
        "id": "UPzj16NZA4C2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ec8519d-dbff-4eea-92f4-25afd7b4cb9a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0029838085174560547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The original sum took approximately 0.006 seconds. The reduced and cleaned matrix took two-thirds of that time or approximately 0.004 seconds."
      ],
      "metadata": {
        "id": "J12XcBB7cOph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. Now consider taking advantage of the missing data in this matrix by storing it as a sparse matrix. Using python's scipy.sparse package, use the csr_matrix function to store the original matrix (without removing distances greater than 50 miles apart) as a sparse matrix. Ensure that the missing values are not stored but all other values (including zeros) are kept. Compute the time it takes to sum all the elements in this new sparse matrix. How does this compare to your previous results?"
      ],
      "metadata": {
        "id": "CP2yTeHJA4Sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "# revert to original matrix by converting the orig DataFrame to a matrix\n",
        "CityDistMatrix = DistMatrix.values\n",
        "data_size = CityDistMatrix.nbytes/(1024**2)\n",
        "print('Original size of matrix: '+ '%3.2f' %data_size + ' MB')\n",
        "\n",
        "#print(CityDistMatrix.shape)\n",
        "unsparseTexas = csr_matrix(CityDistMatrix)\n",
        "data_size = unsparseTexas.data.size/(1024**2)\n",
        "print('Size of full csr matrix with zeros and NaNs: '+ '%3.2f' %data_size + ' MB')\n",
        "\n",
        "#replace values = 0 with -1\n",
        "CityDistMatrix[CityDistMatrix==0] = -1\n",
        "\n",
        "#remove nan values\n",
        "CityDistMatrix = CityDistMatrix[~np.isnan(CityDistMatrix)]\n",
        "\n",
        "sparseTexas = csr_matrix(CityDistMatrix)\n",
        "data_size = sparseTexas.data.size/(1024**2)\n",
        "print('Size of matrix w/o NaNs: '+ '%3.2f' %data_size + ' MB')\n",
        "\n",
        "#replace values = -1 with 0\n",
        "sparseTexas = sparseTexas.toarray() #switch to dense array\n",
        "sparseTexas[sparseTexas==-1] = 0\n",
        "sparseTexas = csr_matrix(sparseTexas)\n",
        "data_size = sparseTexas.data.size/(1024**2)\n",
        "print('Size of matrix w/ explicit zeros: '+ '%3.2f' %data_size + ' MB')\n",
        "\n",
        "start = time.time()\n",
        "print(\"Sum is: \", sparseTexas.sum(axis=None))\n",
        "end = time.time()\n",
        "print(\"It took \", end-start, \" seconds\")"
      ],
      "metadata": {
        "id": "dKjIe3TMA5-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86d66d07-33eb-4786-95a6-1f71cf02fe65"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original size of matrix: 23.42 MB\n",
            "Size of full csr matrix with zeros and NaNs: 2.93 MB\n",
            "Size of matrix w/o NaNs: 0.39 MB\n",
            "Size of matrix w/ explicit zeros: 0.15 MB\n",
            "Sum is:  4504877.859086584\n",
            "It took  0.002202749252319336  seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "f. Knowing that the matrix is symmetric and has zeros along the diagonal, how else could you save storage space? "
      ],
      "metadata": {
        "id": "DMViiqpoA6Pz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the matrix is symmetric, you could also just store the lower or upper triangle of the matrix which would retain only the elements below or above the main diagonal of the Texas City Distance matrix. You could retain or eliminate the diagonal in retention depending on whether you needed that information. In this case, city=city on the diagonal so I assume you would eliminate it to save additional space. In Python, you could store the lower triangle of a matrix with the `np.tril()` function. The `k` parameter of that function indicates whether or not you want to retain the diagonal. This would require additional processing to find matches and distances between cities.\n",
        "\n",
        "Another  option would be to use the eliminate_zeros() and sum_duplicates() function of csr_matrix to remove zero values and then eliminate any duplicate enties by summing them together. As in-place operations, these functions can further reduce the size needed to store the matrix without data loss."
      ],
      "metadata": {
        "id": "1PCIupDzdAtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CityDistMatrix = DistMatrix.values\n",
        "HalfCity = np.tril(CityDistMatrix, k=-1)\n",
        "#replace values = 0 with -1\n",
        "HalfCity[HalfCity==0] = -1\n",
        "\n",
        "#remove nan values\n",
        "HalfCity = HalfCity[~np.isnan(HalfCity)]\n",
        "HalfTexas = csr_matrix(HalfCity)\n",
        "HalfTexas = HalfTexas.toarray() #switch to dense array\n",
        "HalfTexas[HalfTexas==-1] = 0\n",
        "HalfTexas = csr_matrix(HalfTexas)\n",
        "data_size = HalfTexas.data.size/(1024**2)\n",
        "print('Size of matrix- using only lower triangle: '+ '%3.2f' %data_size + ' MB')\n",
        "\n",
        "start = time.time()\n",
        "print(\"Sum is: \", HalfTexas.sum(axis=None))\n",
        "end = time.time()\n",
        "print(\"It took \", end-start, \" seconds\")\n",
        "print(\"\")\n",
        "#replace values = 0 with -1\n",
        "CityDistMatrix[CityDistMatrix==0] = -1\n",
        "\n",
        "#remove nan values\n",
        "CityDistMatrix = CityDistMatrix[~np.isnan(CityDistMatrix)]\n",
        "Texas = csr_matrix(CityDistMatrix)\n",
        "Texas = Texas.toarray() #switch to dense array\n",
        "Texas[Texas==-1] = 0\n",
        "Texas = csr_matrix(Texas)\n",
        "\n",
        "Texas.eliminate_zeros()\n",
        "Texas.sum_duplicates()\n",
        "data_size = Texas.data.size/(1024**2)\n",
        "print('Size of matrix- after using sum_duplicates: '+ '%3.2f' %data_size + ' MB')\n",
        "\n",
        "start = time.time()\n",
        "print(\"Sum is: \", Texas.sum(axis=None))\n",
        "end = time.time()\n",
        "print(\"It took \", end-start, \" seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftQu95tdx8Wo",
        "outputId": "87813cf8-7c18-42ce-ded0-16c20add5757"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of matrix- using only lower triangle: 0.07 MB\n",
            "Sum is:  2252438.929543232\n",
            "It took  0.003416299819946289  seconds\n",
            "\n",
            "Size of matrix- after using sum_duplicates: 0.15 MB\n",
            "Sum is:  4504877.859086584\n",
            "It took  0.001878499984741211  seconds\n"
          ]
        }
      ]
    }
  ]
}